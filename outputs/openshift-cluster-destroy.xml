<?xml version="1.0" encoding="utf-8"?>
<flow-definition plugin="workflow-job">
  <definition class="org.jenkinsci.plugins.workflow.cps.CpsFlowDefinition" plugin="workflow-cps">
    <script>// Jenkins Pipeline for destroying OpenShift clusters on AWS
// Based on Percona's patterns from jenkins-pipelines

pipeline {
    agent {
        label 'built-in'
    }

    environment {
        WORKSPACE_DIR = &quot;${WORKSPACE}&quot;
        CLUSTER_DIR = &quot;${WORKSPACE}/clusters/${params.CLUSTER_NAME}&quot;
        AWS_ACCOUNT_ID = &quot;119175775298&quot;  // From CloudFormation
        S3_BUCKET = &quot;openshift-clusters-119175775298-us-east-2&quot;  // Existing bucket
    }

    stages {
        stage('1. Validate Parameters') {
            steps {
                script {
                    echo &quot;[INFO] Validating destroy parameters...&quot;
                    
                    if (!params.CLUSTER_NAME) {
                        error &quot;[ERROR] Cluster name is required. Please provide the name of the cluster to destroy.&quot;
                    }

                    if (!params.CLUSTER_NAME.matches('^[a-z0-9-]+$')) {
                        error &quot;[ERROR] Invalid cluster name format '\${params.CLUSTER_NAME}'. Use only lowercase letters, numbers, and hyphens.&quot;
                    }
                    
                    echo &quot;[SUCCESS] Parameters validated successfully&quot;
                }
            }
        }

        stage('2. Install OpenShift Tools') {
            steps {
                script {
                    // Verify we're running on x86_64 architecture
                    def currentArch = sh(
                        script: &quot;uname -m&quot;,
                        returnStdout: true
                    ).trim()
                    
                    if (currentArch != 'x86_64') {
                        error &quot;[ERROR] This job requires x86_64 architecture but is running on ${currentArch}. Please ensure the job runs on an AMD64 agent.&quot;
                    }
                    
                    echo &quot;[INFO] Architecture check passed: ${currentArch}&quot;
                    sh &quot;&quot;&quot;
                        echo &quot;[INFO] Installing OpenShift CLI tools...&quot;
                        
                        # Create local bin directory if it doesn't exist
                        mkdir -p ~/bin
                        export PATH=&quot;\$HOME/bin:\$PATH&quot;
                        
                        # Check if tools are already installed and up to date
                        # Use OpenShift 4.19.6 as default version
                        OPENSHIFT_VERSION=&quot;4.19.6&quot;
                        NEED_INSTALL=false
                        
                        if ! command -v openshift-install &amp;&gt; /dev/null; then
                            echo &quot;[INFO] OpenShift installer not found, will install&quot;
                            NEED_INSTALL=true
                        elif ! openshift-install version 2&gt;/dev/null | grep -q &quot;\${OPENSHIFT_VERSION}&quot;; then
                            echo &quot;[INFO] OpenShift installer version mismatch, will reinstall&quot;
                            NEED_INSTALL=true
                        fi
                        
                        if ! command -v oc &amp;&gt; /dev/null; then
                            echo &quot;[INFO] OpenShift CLI client not found, will install&quot;
                            NEED_INSTALL=true
                        fi
                        
                        if [ &quot;\$NEED_INSTALL&quot; = &quot;true&quot; ]; then
                            echo &quot;[INFO] Installing OpenShift \${OPENSHIFT_VERSION} tools...&quot;
                            
                            # Architecture is x86_64 only
                            OPENSHIFT_ARCH=&quot;x86_64&quot;
                            echo &quot;[INFO] Using OpenShift x86_64 binaries&quot;
                            
                            # Download and install openshift-install
                            echo &quot;[INFO] Downloading OpenShift installer...&quot;
                            curl -sL &quot;https://mirror.openshift.com/pub/openshift-v4/\${OPENSHIFT_ARCH}/clients/ocp/\${OPENSHIFT_VERSION}/openshift-install-linux.tar.gz&quot; | tar -xz -C ~/bin/
                            
                            # Download and install oc client  
                            echo &quot;[INFO] Downloading OpenShift CLI client...&quot;
                            curl -sL &quot;https://mirror.openshift.com/pub/openshift-v4/\${OPENSHIFT_ARCH}/clients/ocp/\${OPENSHIFT_VERSION}/openshift-client-linux.tar.gz&quot; | tar -xz -C ~/bin/
                            
                            # Make tools executable
                            chmod +x ~/bin/openshift-install ~/bin/oc
                            
                            echo &quot;[SUCCESS] OpenShift tools installed successfully&quot;
                        else
                            echo &quot;[INFO] OpenShift tools already installed and up to date&quot;
                        fi
                        
                        # Verify installation
                        echo &quot;[INFO] Verifying tool installation...&quot;
                        ~/bin/openshift-install version
                        ~/bin/oc version --client
                    &quot;&quot;&quot;
                    
                    echo &quot;[SUCCESS] OpenShift tools prepared successfully&quot;
                }
            }
        }

        stage('3. Check Prerequisites') {
            steps {
                script {
                    // Verify tools are available (now from ~/bin)
                    sh &quot;&quot;&quot;
                        export PATH=&quot;\$HOME/bin:\$PATH&quot;
                        echo &quot;[INFO] Checking required tools...&quot;
                        which openshift-install || (echo &quot;[ERROR] OpenShift installer not found in PATH&quot; &amp;&amp; exit 1)
                        which oc || (echo &quot;[ERROR] OpenShift CLI client not found in PATH&quot; &amp;&amp; exit 1)
                        which aws || (echo &quot;[ERROR] AWS CLI not found. Please ensure Jenkins agent has AWS CLI installed.&quot; &amp;&amp; exit 1)

                        echo &quot;[INFO] Displaying tool versions...&quot;
                        openshift-install version
                        oc version --client
                        aws --version
                        echo &quot;[SUCCESS] All required tools are available and functional&quot;
                    &quot;&quot;&quot;
                }
            }
        }

        stage('4. Check Cluster Exists') {
            steps {
                script {
                    // Check for local workspace artifacts first (for failed creation attempts)
                    // Check both current workspace and openshift-cluster-create workspace
                    def localClusterExists = sh(
                        script: &quot;&quot;&quot;
                            # Check current workspace
                            (test -d &quot;${WORKSPACE}/clusters/${params.CLUSTER_NAME}&quot; &amp;&amp; \
                             (test -f &quot;${WORKSPACE}/clusters/${params.CLUSTER_NAME}/.openshift_install_state.json&quot; || \
                              test -f &quot;${WORKSPACE}/clusters/${params.CLUSTER_NAME}/metadata.json&quot; || \
                              test -d &quot;${WORKSPACE}/clusters/${params.CLUSTER_NAME}/auth&quot; || \
                              test -d &quot;${WORKSPACE}/clusters/${params.CLUSTER_NAME}/tls&quot;)) || \
                            # Check create job workspace
                            (test -d &quot;/var/lib/jenkins/workspace/openshift-cluster-create/clusters/${params.CLUSTER_NAME}&quot; &amp;&amp; \
                             (test -f &quot;/var/lib/jenkins/workspace/openshift-cluster-create/clusters/${params.CLUSTER_NAME}/.openshift_install_state.json&quot; || \
                              test -f &quot;/var/lib/jenkins/workspace/openshift-cluster-create/clusters/${params.CLUSTER_NAME}/metadata.json&quot; || \
                              test -d &quot;/var/lib/jenkins/workspace/openshift-cluster-create/clusters/${params.CLUSTER_NAME}/auth&quot; || \
                              test -d &quot;/var/lib/jenkins/workspace/openshift-cluster-create/clusters/${params.CLUSTER_NAME}/tls&quot;))
                        &quot;&quot;&quot;,
                        returnStatus: true
                    ) == 0

                    def s3ClusterExists = false
                    withCredentials([
                        [$class: 'AmazonWebServicesCredentialsBinding',
                         credentialsId: 'jenkins-openshift-aws']
                    ]) {
                        s3ClusterExists = sh(
                            script: &quot;&quot;&quot;
                                aws s3 ls s3://${S3_BUCKET}/${params.CLUSTER_NAME}/cluster-state.tar.gz 2&gt;/dev/null
                            &quot;&quot;&quot;,
                            returnStatus: true
                        ) == 0
                    }

                    if (localClusterExists) {
                        echo &quot;[INFO] Found local cluster artifacts for '${params.CLUSTER_NAME}' - will clean up workspace&quot;
                        env.HAS_LOCAL_ARTIFACTS = &quot;true&quot;
                    }

                    if (s3ClusterExists) {
                        echo &quot;[INFO] Found cluster state in S3 for '${params.CLUSTER_NAME}'&quot;
                        env.HAS_S3_ARTIFACTS = &quot;true&quot;
                    }

                    if (!localClusterExists &amp;&amp; !s3ClusterExists) {
                        if (params.DRY_RUN) {
                            echo &quot;[WARNING] DRY RUN: Cluster '${params.CLUSTER_NAME}' not found locally or in S3&quot;
                        } else {
                            error &quot;[ERROR] Cluster '\${params.CLUSTER_NAME}' not found. It may have already been destroyed or never existed. Check 'openshift-cluster-create' job history.&quot;
                        }
                    }

                    // Get cluster metadata
                    if (env.HAS_S3_ARTIFACTS == &quot;true&quot;) {
                        withCredentials([
                            [$class: 'AmazonWebServicesCredentialsBinding',
                             credentialsId: 'jenkins-openshift-aws']
                        ]) {
                            sh &quot;&quot;&quot;
                                echo &quot;[INFO] Retrieving cluster metadata...&quot;
                                aws s3 cp s3://${S3_BUCKET}/${params.CLUSTER_NAME}/metadata.json - | jq '.' || echo &quot;[WARNING] No metadata found in S3&quot;
                            &quot;&quot;&quot;
                        }
                    }
                }
            }
        }

        stage('5. List Resources') {
            steps {
                script {
                    if (params.DRY_RUN) {
                        echo &quot;&quot;
                        echo &quot;========================================&quot;
                        echo &quot;        DRY RUN MODE ACTIVE&quot;
                        echo &quot;========================================&quot;
                        echo &quot;Would destroy cluster: ${params.CLUSTER_NAME}&quot;
                        echo &quot;========================================&quot;
                        echo &quot;&quot;
                    } else {
                        sh &quot;&quot;&quot;
                            echo &quot;[INFO] Resources to be destroyed:&quot;
                            echo &quot;[INFO] - Cluster: ${params.CLUSTER_NAME}&quot;
                            echo &quot;[INFO] - S3 Location: s3://${S3_BUCKET}/${params.CLUSTER_NAME}/&quot;
                            echo &quot;[INFO] - Action: Full cluster destruction&quot;
                        &quot;&quot;&quot;
                        if (params.KEEP_S3_BACKUP) {
                            echo &quot;[INFO]&quot;
                            echo &quot;[WARNING] S3 backup will be preserved after destruction&quot;
                        }
                    }
                }
            }
        }

        stage('6. Destroy Cluster') {
            when {
                expression { !params.DRY_RUN }
            }
            steps {
                script {
                    try {
                        timeout(time: 30, unit: 'MINUTES') {
                            if (env.HAS_LOCAL_ARTIFACTS == &quot;true&quot;) {
                                withCredentials([
                                    [$class: 'AmazonWebServicesCredentialsBinding',
                                     credentialsId: 'jenkins-openshift-aws']
                                ]) {
                                    sh &quot;&quot;&quot;
                                        export PATH=&quot;\$HOME/bin:\$PATH&quot;
                                        echo &quot;[INFO] Cleaning up local workspace artifacts...&quot;
                                        
                                        # Check both possible locations
                                        CLUSTER_DIR_CURRENT=&quot;${WORKSPACE}/clusters/${params.CLUSTER_NAME}&quot;
                                        CLUSTER_DIR_CREATE=&quot;/var/lib/jenkins/workspace/openshift-cluster-create/clusters/${params.CLUSTER_NAME}&quot;
                                        
                                        for CLUSTER_DIR in &quot;\${CLUSTER_DIR_CURRENT}&quot; &quot;\${CLUSTER_DIR_CREATE}&quot;; do
                                            if [ -d &quot;\${CLUSTER_DIR}&quot; ]; then
                                                echo &quot;[INFO] Found cluster directory: \${CLUSTER_DIR}&quot;
                                                
                                                # Try to run openshift-install destroy if possible
                                                if [ -f &quot;\${CLUSTER_DIR}/install-config.yaml&quot; ] || [ -f &quot;\${CLUSTER_DIR}/.openshift_install_state.json&quot; ]; then
                                                    echo &quot;[INFO] Attempting openshift-install destroy...&quot;
                                                    
                                                    # Run destroy directly on the agent
                                                    cd &quot;\${CLUSTER_DIR}&quot;
                                                    openshift-install destroy cluster --log-level=info || echo &quot;[WARNING] openshift-install destroy failed, continuing with manual cleanup&quot;
                                                fi
                                                
                                                echo &quot;[INFO] Removing local cluster directory: \${CLUSTER_DIR}&quot;
                                                rm -rf &quot;\${CLUSTER_DIR}&quot;
                                                echo &quot;[SUCCESS] Local artifacts cleaned up from \${CLUSTER_DIR}&quot;
                                            else
                                                echo &quot;[INFO] No cluster directory found at: \${CLUSTER_DIR}&quot;
                                            fi
                                        done
                                    &quot;&quot;&quot;
                                }
                            }
                            
                            if (env.HAS_S3_ARTIFACTS == &quot;true&quot;) {
                                withCredentials([
                                    [$class: 'AmazonWebServicesCredentialsBinding',
                                     credentialsId: 'jenkins-openshift-aws']
                                ]) {
                                    sh &quot;&quot;&quot;
                                        export PATH=&quot;\$HOME/bin:\$PATH&quot;
                                        echo &quot;[INFO] Processing S3 cluster state...&quot;
                                        
                                        # Download and extract cluster state
                                        mkdir -p &quot;${WORKSPACE}/clusters/${params.CLUSTER_NAME}&quot;
                                        cd &quot;${WORKSPACE}/clusters/${params.CLUSTER_NAME}&quot;
                                        
                                        aws s3 cp s3://${S3_BUCKET}/${params.CLUSTER_NAME}/cluster-state.tar.gz . || {
                                            echo &quot;[ERROR] Failed to download cluster state from S3&quot;
                                            echo &quot;[ERROR] Ensure AWS credentials are valid and cluster exists in S3&quot;
                                            exit 1
                                        }
                                        
                                        tar -xzf cluster-state.tar.gz
                                        
                                        echo &quot;[INFO] Running openshift-install destroy cluster...&quot;
                                        echo &quot;[INFO] This process may take 10-15 minutes...&quot;
                                        
                                        # Navigate to the extracted cluster directory
                                        cd &quot;${WORKSPACE}/clusters/${params.CLUSTER_NAME}/${params.CLUSTER_NAME}&quot;
                                        
                                        # Run destroy directly on the agent
                                        openshift-install destroy cluster --log-level=info
                                        
                                        if [ &quot;${params.KEEP_S3_BACKUP}&quot; != &quot;true&quot; ]; then
                                            echo &quot;[INFO] Removing S3 backup files...&quot;
                                            aws s3 rm s3://${S3_BUCKET}/${params.CLUSTER_NAME}/ --recursive
                                            echo &quot;[SUCCESS] S3 backup files removed&quot;
                                        else
                                            echo &quot;[INFO] Keeping S3 backup files as requested&quot;
                                            echo &quot;[INFO] Files remain at: s3://${S3_BUCKET}/${params.CLUSTER_NAME}/&quot;
                                        fi
                                    &quot;&quot;&quot;
                                }
                            }
                            
                            echo &quot;[SUCCESS] Cluster destruction completed successfully!&quot;
                        }
                    } catch (Exception e) {
                        if (params.FORCE_DESTROY) {
                            echo &quot;[WARNING] Cluster destruction had errors but FORCE_DESTROY is enabled&quot;
                            echo &quot;[WARNING] Error was: ${e.message}&quot;
                            echo &quot;[WARNING] Some resources may not have been fully cleaned up&quot;
                            currentBuild.result = 'UNSTABLE'
                        } else {
                            throw e
                        }
                    }
                }
            }
        }
    }

    post {
        success {
            script {
                if (params.DRY_RUN) {
                    echo &quot;[INFO] DRY RUN completed successfully&quot;
                    echo &quot;[INFO] Cluster '${params.CLUSTER_NAME}' was NOT destroyed (dry run mode)&quot;
                } else {
                    echo &quot;[SUCCESS] OpenShift cluster '${params.CLUSTER_NAME}' destroyed successfully!&quot;
                    if (params.KEEP_S3_BACKUP) {
                        echo &quot;[INFO] S3 backup preserved at: s3://${env.S3_BUCKET}/${params.CLUSTER_NAME}/&quot;
                    }
                }
            }
        }

        failure {
            echo &quot;[ERROR] Failed to destroy OpenShift cluster '${params.CLUSTER_NAME}'&quot;
            echo &quot;[ERROR] Review the logs above for detailed error information.&quot;
            echo &quot;[ERROR] You may need to manually clean up AWS resources using the AWS console.&quot;
        }

        cleanup {
            script {
                // Clean up workspace
                sh &quot;&quot;&quot;
                    echo &quot;[INFO] Cleaning up workspace...&quot;
                    if [ &quot;${params.DRY_RUN}&quot; != &quot;true&quot; ]; then
                        rm -rf ${WORKSPACE}/clusters/${params.CLUSTER_NAME}
                    fi
                    rm -f ${WORKSPACE}/clusters/*.tar.gz
                    echo &quot;[SUCCESS] Workspace cleanup completed&quot;
                &quot;&quot;&quot;
            }
        }
    }
}
</script>
    <sandbox>false</sandbox>
  </definition>
  <actions/>
  <description>Destroy OpenShift clusters on AWS safely and completely.

This job:
- Downloads cluster state from S3
- Lists all resources to be destroyed
- Performs clean cluster destruction
- Verifies complete cleanup
- Optionally keeps S3 backups

Supports dry-run mode for safe testing.
&lt;!-- Managed by Jenkins Job Builder --&gt;</description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <org.jenkinsci.plugins.workflow.job.properties.DisableConcurrentBuildsJobProperty/>
    <jenkins.model.BuildDiscarderProperty>
      <strategy class="hudson.tasks.LogRotator">
        <daysToKeep>30</daysToKeep>
        <numToKeep>20</numToKeep>
        <artifactDaysToKeep>-1</artifactDaysToKeep>
        <artifactNumToKeep>-1</artifactNumToKeep>
      </strategy>
    </jenkins.model.BuildDiscarderProperty>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.StringParameterDefinition>
          <name>CLUSTER_NAME</name>
          <description>Name of the OpenShift cluster to destroy</description>
          <defaultValue/>
          <trim>true</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
          <name>FORCE_DESTROY</name>
          <description>Force destroy even if there are errors</description>
          <defaultValue>false</defaultValue>
        </hudson.model.BooleanParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
          <name>KEEP_S3_BACKUP</name>
          <description>Keep the cluster state backup in S3 after destruction</description>
          <defaultValue>false</defaultValue>
        </hudson.model.BooleanParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
          <name>DRY_RUN</name>
          <description>Show what would be destroyed without actually destroying</description>
          <defaultValue>false</defaultValue>
        </hudson.model.BooleanParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
    <org.jenkinsci.plugins.workflow.job.properties.PipelineTriggersJobProperty>
      <triggers>
        <hudson.triggers.TimerTrigger>
          <spec/>
        </hudson.triggers.TimerTrigger>
      </triggers>
    </org.jenkinsci.plugins.workflow.job.properties.PipelineTriggersJobProperty>
  </properties>
</flow-definition>
